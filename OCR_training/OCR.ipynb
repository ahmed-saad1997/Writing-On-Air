{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcif8BL3erLx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device=torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "H0G8_wk2iRZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d nibinv23/iam-handwriting-word-database"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc-Hw1k9ijih",
        "outputId": "631e30b9-c9ce-43f0-85b5-efdd7f9787af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading iam-handwriting-word-database.zip to /content\n",
            "100% 1.10G/1.10G [00:34<00:00, 34.7MB/s]\n",
            "100% 1.10G/1.10G [00:34<00:00, 34.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q iam-handwriting-word-database.zip"
      ],
      "metadata": {
        "id": "R71ukkypivXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "img_paths=[]\n",
        "for i in os.listdir('iam_words/words'):\n",
        "  for j in os.listdir('iam_words/words/'+i):\n",
        "    for x in os.listdir('iam_words/words/'+i+'/'+j):\n",
        "      img_paths.append('iam_words/words/'+i+'/'+j+'/'+x)\n",
        "len(img_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oisuj5Ri1kx",
        "outputId": "4537fb3a-aac7-4715-d0b5-38c6d56ef3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115320"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imgs_labels={}\n",
        "with open('words_new.txt','r') as labels_txt:\n",
        "  lines=labels_txt.readlines()\n",
        "  for i in range(18,len(lines)):\n",
        "    if lines[i].split(' ')[1].strip()!='ok' or len(lines[i].split(' ')[-1].strip())<=1:\n",
        "      continue\n",
        "    img_name=lines[i].strip().split(' ')[0].strip()\n",
        "    label=lines[i].split(' ')[-1].strip()\n",
        "    imgs_labels[img_name]=label\n",
        "    if i==20:\n",
        "      print('`'+img_name+'`','`'+label+'`')\n",
        "\n",
        "len(imgs_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eH6ddpYkAqp",
        "outputId": "92344461-0819-48b0-b8cb-fc15579afaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "`a01-000u-00-02` `to`\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33273"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab=[chr(a) for a in range(ord('a'),ord('z')+1)]+[chr(a) for a in range(ord('A'),ord('Z')+1)]\n",
        "for i in imgs_labels:\n",
        "  for x in imgs_labels[i]:\n",
        "    if x not in vocab:\n",
        "      vocab.append(x)\n",
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8xz-TCxoioP",
        "outputId": "466fea70-a6ce-49eb-eab2-dfc2eeece499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '.', '-', \"'\", '1', '9', '5', '8', '3', '4', '0', ',', '2', '7', '6', '/', '*', '?', '\"']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir preproc_img"
      ],
      "metadata": {
        "id": "_OKBGnGgqWwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "def img_reshape(img,name):\n",
        "  shape=(32,128)\n",
        "  target = np.ones(shape)*255\n",
        "  H, W = shape\n",
        "  h, w = img.shape\n",
        "  fx = H/h\n",
        "  fy = W/w\n",
        "  f = min(fx, fy)\n",
        "  _h = int(h*f)\n",
        "  _w = int(w*f)\n",
        "  _img = cv2.resize(img, (_w,_h))\n",
        "  target[:_h,:_w] = _img\n",
        "  cv2.imwrite(name,target)\n",
        "i=0\n",
        "for im in img_paths:\n",
        "  img_name=im.split('/')[-1].strip().split('.')[0]\n",
        "  if img_name in imgs_labels:\n",
        "    img=cv2.imread(im)\n",
        "    try:\n",
        "      if len(img.shape)==3:\n",
        "        img=cv2.imread(im,0)\n",
        "      img_reshape(img,'preproc_img/'+imgs_labels[img_name]+'@IAM'+str(i)+'.png')\n",
        "      i+=1\n",
        "    except:\n",
        "      print(im)\n",
        "len(os.listdir('preproc_img'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BreLzt-wmDMr",
        "outputId": "398d489c-933a-484d-c865-8c40d0c62039"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iam_words/words/a01/a01-117/a01-117-05-02.png\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33263"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "disnNsdYDqaQ",
        "outputId": "fe9daceb-0add-4a89-fd96-e0009a10767d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-12 00:11:41--  https://www.dropbox.com/s/l2ul3upj7dkv4ou/synthetic-data.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.18, 2620:100:6021:18::a27d:4112\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/l2ul3upj7dkv4ou/synthetic-data.zip [following]\n",
            "--2023-07-12 00:11:42--  https://www.dropbox.com/s/raw/l2ul3upj7dkv4ou/synthetic-data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com/cd/0/inline/B_vWHwpUph_-fPJfB69fhOzpUQ5aOUK0LCAZ_AOrR2G0ukTuqydftOZUcp36MXtF-kfb0ZBhvZxTCPyHDb1F85DyhxrqJC9ivdOmO0IrlxqTosNmpyjtworGAZOBDZJCgfIkwFEGZ_F1oYyIcvLG3iZcWs21Drs4N3yNmu51KelrkA/file# [following]\n",
            "--2023-07-12 00:11:42--  https://uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com/cd/0/inline/B_vWHwpUph_-fPJfB69fhOzpUQ5aOUK0LCAZ_AOrR2G0ukTuqydftOZUcp36MXtF-kfb0ZBhvZxTCPyHDb1F85DyhxrqJC9ivdOmO0IrlxqTosNmpyjtworGAZOBDZJCgfIkwFEGZ_F1oYyIcvLG3iZcWs21Drs4N3yNmu51KelrkA/file\n",
            "Resolving uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com (uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com)... 162.125.65.15, 2620:100:6027:15::a27d:480f\n",
            "Connecting to uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com (uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com)|162.125.65.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/B_uQtS0lRO6_41eVS20Ldj81l3F1skxyuJW98nslLtdvASOefMmVusx6nkhP2jazrviwMbpAv0mb5VIsx0rs2NyfHb4XwywPY4qTCoMIRWc3zNCU2IG7vuL-PhDWPMjf4fwsTzCWE6XkeqDVuQ_ZnPk7BnmY3W1-W0ISu59FM7kEURh9yEZMsV46sUGLIqmyFU2SW3UN3CES_8pOGkKeMuq7jaqyHO9SZNu8Whe9by6h_rQtAtuXf9hhjE3nxj8npNpgUYODF2ChnhzbKgrkVvhFZViHyT-_0T-xHiCGhSyyHsKqNfCuAlE9qlFQunFNkGwcnjkC-YGtlAwmAAia7V2C6Pj3q5mhTXEDX8YqS1bzwUgFC-gV75u82jN0JryvuDUOG-R7FolI8ubLVevffVg9nRwK-OVzQNGoCUdmMjpG6g/file [following]\n",
            "--2023-07-12 00:11:43--  https://uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com/cd/0/inline2/B_uQtS0lRO6_41eVS20Ldj81l3F1skxyuJW98nslLtdvASOefMmVusx6nkhP2jazrviwMbpAv0mb5VIsx0rs2NyfHb4XwywPY4qTCoMIRWc3zNCU2IG7vuL-PhDWPMjf4fwsTzCWE6XkeqDVuQ_ZnPk7BnmY3W1-W0ISu59FM7kEURh9yEZMsV46sUGLIqmyFU2SW3UN3CES_8pOGkKeMuq7jaqyHO9SZNu8Whe9by6h_rQtAtuXf9hhjE3nxj8npNpgUYODF2ChnhzbKgrkVvhFZViHyT-_0T-xHiCGhSyyHsKqNfCuAlE9qlFQunFNkGwcnjkC-YGtlAwmAAia7V2C6Pj3q5mhTXEDX8YqS1bzwUgFC-gV75u82jN0JryvuDUOG-R7FolI8ubLVevffVg9nRwK-OVzQNGoCUdmMjpG6g/file\n",
            "Reusing existing connection to uc94bd024abcfa4f4e04f690997b.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 39876999 (38M) [application/zip]\n",
            "Saving to: ‘synthetic-data.zip’\n",
            "\n",
            "synthetic-data.zip  100%[===================>]  38.03M  28.1MB/s    in 1.4s    \n",
            "\n",
            "2023-07-12 00:11:45 (28.1 MB/s) - ‘synthetic-data.zip’ saved [39876999/39876999]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/l2ul3upj7dkv4ou/synthetic-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bih4F1eqD7an"
      },
      "outputs": [],
      "source": [
        "!unzip -q synthetic-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZK1xj0emzgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a7161dc-c3e5-4fc8-a4c6-abc8c4d31300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s', 'm', 'a', 'l', 'l', 'w', 'i', 'n', 'h', 'u', 'b', 'd', 't', 'e', 'c', 'e', 'r', 'f', 'o', 'o', 'T', 'V', 'p', 'z', 'g', 'y', 'v', 'k', 'x', 'j', 'q', 'C', 'R', 'I', 'A', 'P', 'M', 'D']\n",
            "14\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "words=[a.strip().split('@')[0] for a in os.listdir('synthetic-data')]\n",
        "chars=[]\n",
        "max_len=0\n",
        "for word in words:\n",
        "  max_len=len(word) if len(word)>max_len else max_len\n",
        "  chars.extend([ch for ch in word if ch not in chars])\n",
        "print(chars)\n",
        "print(max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iYD0Sx507ee"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "def img_reshape(img,name):\n",
        "  shape=(32,128)\n",
        "  target = np.ones(shape)*255\n",
        "  H, W = shape\n",
        "  h, w = img.shape\n",
        "  fx = H/h\n",
        "  fy = W/w\n",
        "  f = min(fx, fy)\n",
        "  _h = int(h*f)\n",
        "  _w = int(w*f)\n",
        "  _img = cv2.resize(img, (_w,_h))\n",
        "  target[:_h,:_w] = _img\n",
        "  cv2.imwrite(name,target)\n",
        "for im in os.listdir('synthetic-data'):\n",
        "  img=cv2.imread('synthetic-data/'+im,0)\n",
        "  img_reshape(img,'preproc_img/'+im)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO1Cn6aKpGnq"
      },
      "outputs": [],
      "source": [
        "!pip install -q editdistance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F4_cT3HFTZH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import cv2\n",
        "import editdistance\n",
        "import random\n",
        "class dataset(Dataset):\n",
        "  def __init__(self,data,timestep=32,img_size=(32,128)):\n",
        "    super().__init__()\n",
        "    self.data=data\n",
        "    self.timestep=timestep\n",
        "    self.img_size=img_size\n",
        "    self.vocap=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '.', '-', \"'\", '1', '9', '5', '8', '3', '4', '0', ',', '2', '7', '6', '/', '*', '?', '\"']\n",
        "    self.char_code={x:i+1 for i,x in enumerate(self.vocap)}\n",
        "    self.char_code.update({'-':0})\n",
        "    self.code_char={i+1:x for i,x in enumerate(self.vocap)}\n",
        "    self.code_char.update({0:'-'})\n",
        "  def pad(self,code,max_len):\n",
        "    padded_item = code + [0]*(max_len-len(code))\n",
        "    return padded_item\n",
        "  def sample(self):\n",
        "    return self[random.randint(0,len(self))]\n",
        "  def get_image_label(self,image_name):\n",
        "    return image_name.strip().split('@')[0]\n",
        "  def get_label_code(self,label):\n",
        "    return [self.char_code[x] for x in label]\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, index):\n",
        "    item=self.data[index]\n",
        "    image=cv2.imread('preproc_img/'+item,0)\n",
        "    label=self.get_image_label(item)\n",
        "    return image,label\n",
        "  def collate_fn(self, batch):\n",
        "    images, labels, label_lengths, label_vectors, input_lengths = [], [], [], [], []\n",
        "    for image, label in batch:\n",
        "        images.append(torch.Tensor(image)[None,None])\n",
        "        label_lengths.append(len(label))\n",
        "        labels.append(label)\n",
        "        label_code=self.get_label_code(label)\n",
        "        padded=self.pad(label_code,self.timestep)\n",
        "        label_vectors.append(padded)\n",
        "        input_lengths.append(self.timestep)\n",
        "    images = torch.cat(images).float().to(device)\n",
        "    label_lengths = torch.Tensor(label_lengths).long().to(device)\n",
        "    label_vectors = torch.Tensor(label_vectors).long().to(device)\n",
        "    input_lengths = torch.Tensor(input_lengths).long().to(device)\n",
        "    return images, labels, label_lengths,label_vectors,  input_lengths\n",
        "  def wer(self, preds, labels):\n",
        "      c = 0\n",
        "      for p, l in zip(preds, labels):\n",
        "          c += p.lower().strip() != l.lower().strip()\n",
        "      return round(c/len(preds), 4)\n",
        "  def cer(self, preds, labels):\n",
        "      c, d = [], []\n",
        "      for p, l in zip(preds, labels):\n",
        "          c.append(editdistance.eval(p, l) / len(l))\n",
        "      return round(np.mean(c), 4)\n",
        "  def decode(self, pred):\n",
        "      decoded = \"\"\n",
        "      last = \"\"\n",
        "      pred = pred.cpu().detach().numpy()\n",
        "      for i in range(len(pred)):\n",
        "          k = np.argmax(pred[i])\n",
        "          if k > 0 and self.code_char[k] != last:\n",
        "              last = self.code_char[k]\n",
        "              decoded = decoded + last\n",
        "          elif k > 0 and self.code_char[k] == last:\n",
        "              continue\n",
        "          else:\n",
        "              last = \"\"\n",
        "      return decoded.replace(\" \",\"\")\n",
        "  def evaluate(self, model, ims, labels, lower=False):\n",
        "      model.eval()\n",
        "      preds = model(ims).permute(1,0,2)\n",
        "      preds = [self.decode(pred) for pred in preds]\n",
        "      return {'char-error-rate': self.cer(preds, labels),\n",
        "              'word-error-rate': self.wer(preds, labels),\n",
        "              'char-accuracy' : 1 - self.cer(preds, labels),\n",
        "              'word-accuracy' : 1 - self.wer(preds, labels)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmIxNq7P5BeR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1064e90b-f382-49ed-d3ee-4a1393b1c991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58395\n",
            "46716\n",
            "11679\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "batch=64\n",
        "data=os.listdir('preproc_img')\n",
        "trn,val=train_test_split(data,test_size=0.2,random_state=22)\n",
        "print(len(data))\n",
        "print(len(trn))\n",
        "print(len(val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import shutil\n",
        "paths= os.listdir('preproc_img')\n",
        "for i in range(5):\n",
        "  pat=paths[random.randint(0,len(paths))]\n",
        "  shutil.copy('preproc_img/'+pat,pat)"
      ],
      "metadata": {
        "id": "UDFEW4bl3VXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuAmTy-eSza7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image,ImageOps\n",
        "import numpy as np\n",
        "rotate_transform =transforms.RandomRotation(degrees=5)\n",
        "affine_transform=transforms.RandomAffine(degrees=5, translate=(0.01, 0.01), shear=10)\n",
        "gaussblur_transform=transforms.GaussianBlur(kernel_size=3, sigma=(0.1, 2.0))\n",
        "\n",
        "trans=[rotate_transform,affine_transform,gaussblur_transform]\n",
        "aug_trn=[]\n",
        "aug_val=[]\n",
        "def zoom_out(path,pad,aug_list,ind):\n",
        "    img = Image.open('preproc_img/'+path)\n",
        "    padding = pad\n",
        "    width, height = img.size\n",
        "    new_width = width + 2 * padding\n",
        "    new_height = height + 2 * padding\n",
        "    bordered_img = ImageOps.expand(img, border=padding, fill='white')\n",
        "    img_zoom_out = bordered_img.resize((128, 32))\n",
        "    try:\n",
        "      img_zoom_out.save('preproc_img/'+path.split('@')[0]+'@zoom'+str(pad)+str(ind)+path.split('@')[1], format=path.split('.')[-1])\n",
        "    except:\n",
        "      print(path)\n",
        "    aug_list.append(path.split('@')[0]+'@zoom'+str(pad)+str(ind)+path.split('@')[1])\n",
        "for path in trn:\n",
        "    zoom_out(path,25,aug_trn,1)\n",
        "    zoom_out(path,10,aug_trn,2)\n",
        "for path in val:\n",
        "    zoom_out(path,25,aug_val,3)\n",
        "    zoom_out(path,10,aug_val,4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIHzKOTuTbgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24dfba0a-531e-4e72-f89f-6b7f2d5067e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175185\n",
            "140148\n",
            "35037\n"
          ]
        }
      ],
      "source": [
        "trn+=aug_trn\n",
        "val+=aug_val\n",
        "print(len(os.listdir('preproc_img')))\n",
        "print(len(trn))\n",
        "print(len(val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORXeAm9hixuT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5760c15d-00c0-4465-b5f9-4e88506190cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2189\n",
            "547\n"
          ]
        }
      ],
      "source": [
        "trn_dataset=dataset(trn)\n",
        "val_dataset=dataset(val)\n",
        "trn_loader=DataLoader(trn_dataset,collate_fn=trn_dataset.collate_fn,batch_size=batch,drop_last=True,shuffle=True)\n",
        "val_loader=DataLoader(val_dataset,collate_fn=val_dataset.collate_fn,batch_size=batch,drop_last=True)\n",
        "print(len(trn_loader))\n",
        "print(len(val_loader))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ifeW3Fx6i3V",
        "outputId": "b0372796-d065-4a58-c8b3-1371f855b66f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gNMhwpamiS7M"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "class OCRmodel(nn.Module):\n",
        "  def __init__(self,ks=3,st=1,pad=1,pool=2, drop=0.2,vocab_len=70):\n",
        "    super().__init__()\n",
        "    self.model=nn.Sequential(\n",
        "        nn.Conv2d(1, 128, kernel_size=ks, stride=st, padding=pad),\n",
        "        nn.BatchNorm2d(128, momentum=0.3),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(pool),\n",
        "        nn.Dropout2d(drop),\n",
        "        nn.Conv2d(128, 128, kernel_size=ks, stride=st, padding=pad),\n",
        "        nn.BatchNorm2d(128, momentum=0.3),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d(pool),\n",
        "        nn.Dropout2d(drop),\n",
        "        nn.Conv2d(128, 256, kernel_size=ks, stride=st, padding=pad),\n",
        "        nn.BatchNorm2d(256, momentum=0.3),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.MaxPool2d((4,2)),\n",
        "        nn.Dropout2d(drop)\n",
        "    )\n",
        "    self.rnn=nn.Sequential(\n",
        "        nn.LSTM(256, 256, num_layers=2, dropout=0.2, bidirectional=True)\n",
        "    )\n",
        "    self.classification = nn.Sequential(\n",
        "        nn.Linear(512, vocab_len+1),\n",
        "        nn.LogSoftmax(-1),\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    x=self.model(x)\n",
        "    x=x.reshape(-1, 256, 32)\n",
        "    x=x.permute(2,0,1)\n",
        "    x,ls=self.rnn(x)\n",
        "    x=self.classification(x)\n",
        "    return x\n",
        "def ctc(log_probs, target, input_lengths, target_lengths, blank=0):\n",
        "    loss = nn.CTCLoss(blank=blank, zero_infinity=True)\n",
        "    ctc_loss = loss(log_probs, target, input_lengths, target_lengths)\n",
        "    return ctc_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4TlI_tGsi6J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd807960-6337-411b-cf3e-a89dc55af5bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.8/202.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.8/98.8 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q torch_summary\n",
        "!pip install -q torch_snippets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMDIdBfPqEAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393329c0-66dc-4c24-be3c-593c7d0231b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==========================================================================================\n",
            "Layer (type:depth-idx)                   Output Shape              Param #\n",
            "==========================================================================================\n",
            "├─Sequential: 1-1                        [-1, 256, 2, 16]          --\n",
            "|    └─Conv2d: 2-1                       [-1, 128, 32, 128]        1,280\n",
            "|    └─BatchNorm2d: 2-2                  [-1, 128, 32, 128]        256\n",
            "|    └─ReLU: 2-3                         [-1, 128, 32, 128]        --\n",
            "|    └─MaxPool2d: 2-4                    [-1, 128, 16, 64]         --\n",
            "|    └─Dropout2d: 2-5                    [-1, 128, 16, 64]         --\n",
            "|    └─Conv2d: 2-6                       [-1, 128, 16, 64]         147,584\n",
            "|    └─BatchNorm2d: 2-7                  [-1, 128, 16, 64]         256\n",
            "|    └─ReLU: 2-8                         [-1, 128, 16, 64]         --\n",
            "|    └─MaxPool2d: 2-9                    [-1, 128, 8, 32]          --\n",
            "|    └─Dropout2d: 2-10                   [-1, 128, 8, 32]          --\n",
            "|    └─Conv2d: 2-11                      [-1, 256, 8, 32]          295,168\n",
            "|    └─BatchNorm2d: 2-12                 [-1, 256, 8, 32]          512\n",
            "|    └─ReLU: 2-13                        [-1, 256, 8, 32]          --\n",
            "|    └─MaxPool2d: 2-14                   [-1, 256, 2, 16]          --\n",
            "|    └─Dropout2d: 2-15                   [-1, 256, 2, 16]          --\n",
            "├─Sequential: 1-2                        [-1, 1, 512]              --\n",
            "|    └─LSTM: 2-16                        [-1, 1, 512]              2,629,632\n",
            "├─Sequential: 1-3                        [-1, 1, 71]               --\n",
            "|    └─Linear: 2-17                      [-1, 1, 71]               36,423\n",
            "|    └─LogSoftmax: 2-18                  [-1, 1, 71]               --\n",
            "==========================================================================================\n",
            "Total params: 3,111,111\n",
            "Trainable params: 3,111,111\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 236.97\n",
            "==========================================================================================\n",
            "Input size (MB): 0.02\n",
            "Forward/backward pass size (MB): 11.00\n",
            "Params size (MB): 11.87\n",
            "Estimated Total Size (MB): 22.89\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "├─Sequential: 1-1                        [-1, 256, 2, 16]          --\n",
              "|    └─Conv2d: 2-1                       [-1, 128, 32, 128]        1,280\n",
              "|    └─BatchNorm2d: 2-2                  [-1, 128, 32, 128]        256\n",
              "|    └─ReLU: 2-3                         [-1, 128, 32, 128]        --\n",
              "|    └─MaxPool2d: 2-4                    [-1, 128, 16, 64]         --\n",
              "|    └─Dropout2d: 2-5                    [-1, 128, 16, 64]         --\n",
              "|    └─Conv2d: 2-6                       [-1, 128, 16, 64]         147,584\n",
              "|    └─BatchNorm2d: 2-7                  [-1, 128, 16, 64]         256\n",
              "|    └─ReLU: 2-8                         [-1, 128, 16, 64]         --\n",
              "|    └─MaxPool2d: 2-9                    [-1, 128, 8, 32]          --\n",
              "|    └─Dropout2d: 2-10                   [-1, 128, 8, 32]          --\n",
              "|    └─Conv2d: 2-11                      [-1, 256, 8, 32]          295,168\n",
              "|    └─BatchNorm2d: 2-12                 [-1, 256, 8, 32]          512\n",
              "|    └─ReLU: 2-13                        [-1, 256, 8, 32]          --\n",
              "|    └─MaxPool2d: 2-14                   [-1, 256, 2, 16]          --\n",
              "|    └─Dropout2d: 2-15                   [-1, 256, 2, 16]          --\n",
              "├─Sequential: 1-2                        [-1, 1, 512]              --\n",
              "|    └─LSTM: 2-16                        [-1, 1, 512]              2,629,632\n",
              "├─Sequential: 1-3                        [-1, 1, 71]               --\n",
              "|    └─Linear: 2-17                      [-1, 1, 71]               36,423\n",
              "|    └─LogSoftmax: 2-18                  [-1, 1, 71]               --\n",
              "==========================================================================================\n",
              "Total params: 3,111,111\n",
              "Trainable params: 3,111,111\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 236.97\n",
              "==========================================================================================\n",
              "Input size (MB): 0.02\n",
              "Forward/backward pass size (MB): 11.00\n",
              "Params size (MB): 11.87\n",
              "Estimated Total Size (MB): 22.89\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "from torch_snippets import Report\n",
        "model=OCRmodel()\n",
        "model.to(device)\n",
        "summary(model, torch.zeros((1,1,32,128)).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBr66V3VyM21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91cedb0b-f9f4-4f80-9da3-a1b0eba9ede5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EPOCH: 46.000  validation_loss: 0.203  validation_char_acc: 0.953  validation_word_acc: 0.844  (21163.99s - 24844.68s remaining)saving best weights -- epoch 45\n",
            "\n",
            "EPOCH: 46.000  train_loss: 0.128  validation_loss: 0.294  validation_char_acc: 0.927  validation_word_acc: 0.782  train_char_acc: 0.987  train_word_acc: 0.936  (21164.22s - 24844.95s remaining)\n",
            "\n",
            "Pred: `Sany` :: Truth: `Barry`\n",
            "Pred: `away` :: Truth: `away`\n",
            "Pred: `if` :: Truth: `if`\n",
            "Pred: `to` :: Truth: `to`\n",
            "Pred: `on` :: Truth: `on`\n",
            "test img: rixe\n",
            "\n",
            "EPOCH: 47.000  train_loss: 0.123  validation_loss: 0.307  validation_char_acc: 0.924  validation_word_acc: 0.778  train_char_acc: 0.987  train_word_acc: 0.937  (21363.62s - 24090.90s remaining)\n",
            "\n",
            "Pred: `this` :: Truth: `this`\n",
            "Pred: `today` :: Truth: `today`\n",
            "Pred: `firmge` :: Truth: `through`\n",
            "Pred: `says` :: Truth: `says`\n",
            "Pred: `Wed` :: Truth: `West`\n",
            "test img: pie\n",
            "\n",
            "EPOCH: 48.000  validation_loss: 0.243  validation_char_acc: 0.939  validation_word_acc: 0.844  (21561.39s - 23358.17s remaining)saving best weights -- epoch 47\n",
            "\n",
            "EPOCH: 48.000  train_loss: 0.125  validation_loss: 0.291  validation_char_acc: 0.926  validation_word_acc: 0.783  train_char_acc: 0.987  train_word_acc: 0.935  (21561.52s - 23358.31s remaining)\n",
            "\n",
            "Pred: `enjoy` :: Truth: `enjoy`\n",
            "Pred: `sperding` :: Truth: `spending`\n",
            "Pred: `He` :: Truth: `He`\n",
            "Pred: `his` :: Truth: `his`\n",
            "Pred: `Wesr` :: Truth: `West`\n",
            "test img: PiR\n",
            "\n",
            "EPOCH: 49.000  validation_loss: 0.272  validation_char_acc: 0.948  validation_word_acc: 0.844  (21759.27s - 22647.41s remaining)saving best weights -- epoch 48\n",
            "\n",
            "EPOCH: 49.000  train_loss: 0.122  validation_loss: 0.296  validation_char_acc: 0.926  validation_word_acc: 0.783  train_char_acc: 0.988  train_word_acc: 0.937  (21759.41s - 22647.55s remaining)\n",
            "\n",
            "Pred: `social` :: Truth: `social`\n",
            "Pred: `side` :: Truth: `side`\n",
            "Pred: `through` :: Truth: `through`\n",
            "Pred: `through` :: Truth: `through`\n",
            "Pred: `anyway` :: Truth: `anyway`\n",
            "test img: rie\n",
            "\n",
            "EPOCH: 50.000  train_loss: 0.123  validation_loss: 0.299  validation_char_acc: 0.925  validation_word_acc: 0.783  train_char_acc: 0.987  train_word_acc: 0.936  (21959.07s - 21959.07s remaining)\n",
            "\n",
            "Pred: `really` :: Truth: `really`\n",
            "Pred: `study` :: Truth: `study`\n",
            "Pred: `producton` :: Truth: `production`\n",
            "Pred: `traditional` :: Truth: `traditional`\n",
            "Pred: `To` :: Truth: `To`\n",
            "test img: plce\n",
            "\n",
            "EPOCH: 51.000  validation_loss: 0.490  validation_char_acc: 0.899  validation_word_acc: 0.828  (22157.42s - 21288.50s remaining)saving best weights -- epoch 50\n",
            "\n",
            "EPOCH: 51.000  train_loss: 0.124  validation_loss: 0.290  validation_char_acc: 0.927  validation_word_acc: 0.784  train_char_acc: 0.988  train_word_acc: 0.938  (22157.56s - 21288.64s remaining)\n",
            "\n",
            "Pred: `number` :: Truth: `number`\n",
            "Pred: `loss` :: Truth: `loss`\n",
            "Pred: `list` :: Truth: `list`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `acs` :: Truth: `acts`\n",
            "test img: rire\n",
            "\n",
            "EPOCH: 52.000  train_loss: 0.121  validation_loss: 0.305  validation_char_acc: 0.925  validation_word_acc: 0.778  train_char_acc: 0.988  train_word_acc: 0.939  (22356.92s - 20637.16s remaining)\n",
            "\n",
            "Pred: `Cheise` :: Truth: `Christ`\n",
            "Pred: `force` :: Truth: `force`\n",
            "Pred: `Wicki` :: Truth: `Wicki`\n",
            "Pred: `last` :: Truth: `last`\n",
            "Pred: `need` :: Truth: `need`\n",
            "test img: tie\n",
            "\n",
            "EPOCH: 53.000  train_loss: 0.123  validation_loss: 0.298  validation_char_acc: 0.925  validation_word_acc: 0.779  train_char_acc: 0.988  train_word_acc: 0.939  (22555.47s - 20002.02s remaining)\n",
            "\n",
            "Pred: `new` :: Truth: `new`\n",
            "Pred: `now` :: Truth: `now`\n",
            "Pred: `in` :: Truth: `in`\n",
            "Pred: `onritly` :: Truth: `pretty`\n",
            "Pred: `situations` :: Truth: `situations`\n",
            "test img: MIe\n",
            "\n",
            "EPOCH: 54.000  train_loss: 0.120  validation_loss: 0.289  validation_char_acc: 0.927  validation_word_acc: 0.784  train_char_acc: 0.988  train_word_acc: 0.939  (22755.58s - 19384.38s remaining)\n",
            "\n",
            "Pred: `need` :: Truth: `need`\n",
            "Pred: `said` :: Truth: `said`\n",
            "Pred: `also` :: Truth: `also`\n",
            "Pred: `moe` :: Truth: `use`\n",
            "Pred: `the` :: Truth: `the`\n",
            "test img: Aie\n",
            "\n",
            "EPOCH: 55.000  train_loss: 0.121  validation_loss: 0.294  validation_char_acc: 0.926  validation_word_acc: 0.782  train_char_acc: 0.988  train_word_acc: 0.939  (22955.55s - 18781.81s remaining)\n",
            "\n",
            "Pred: `most` :: Truth: `most`\n",
            "Pred: `added` :: Truth: `added`\n",
            "Pred: `servics` :: Truth: `Services`\n",
            "Pred: `identify` :: Truth: `identify`\n",
            "Pred: `policy` :: Truth: `policy`\n",
            "test img: pire\n",
            "\n",
            "EPOCH: 56.000  train_loss: 0.121  validation_loss: 0.316  validation_char_acc: 0.923  validation_word_acc: 0.775  train_char_acc: 0.988  train_word_acc: 0.939  (23155.16s - 18193.34s remaining)\n",
            "\n",
            "Pred: `weapon` :: Truth: `weapons`\n",
            "Pred: `Mr` :: Truth: `Mr`\n",
            "Pred: `coming` :: Truth: `coming`\n",
            "Pred: `of` :: Truth: `of`\n",
            "Pred: `open` :: Truth: `open`\n",
            "test img: pie\n",
            "\n",
            "EPOCH: 57.000  train_loss: 0.120  validation_loss: 0.287  validation_char_acc: 0.926  validation_word_acc: 0.783  train_char_acc: 0.987  train_word_acc: 0.937  (23353.49s - 17617.54s remaining)\n",
            "\n",
            "Pred: `Uniset` :: Truth: `United`\n",
            "Pred: `woord` :: Truth: `word`\n",
            "Pred: `mean` :: Truth: `mean`\n",
            "Pred: `opaeration` :: Truth: `operation`\n",
            "Pred: `outside` :: Truth: `outside`\n",
            "test img: pire\n",
            "\n",
            "EPOCH: 58.000  validation_loss: 0.252  validation_char_acc: 0.940  validation_word_acc: 0.812  (23554.98s - 17057.05s remaining)saving best weights -- epoch 57\n",
            "\n",
            "EPOCH: 58.000  train_loss: 0.117  validation_loss: 0.289  validation_char_acc: 0.929  validation_word_acc: 0.786  train_char_acc: 0.989  train_word_acc: 0.941  (23555.14s - 17057.17s remaining)\n",
            "\n",
            "Pred: `image` :: Truth: `image`\n",
            "Pred: `rock` :: Truth: `rock`\n",
            "Pred: `where` :: Truth: `where`\n",
            "Pred: `that` :: Truth: `that`\n",
            "Pred: `Fost` :: Truth: `First`\n",
            "test img: pire\n",
            "\n",
            "EPOCH: 59.000  validation_loss: 0.446  validation_char_acc: 0.900  validation_word_acc: 0.828  (23754.04s - 16507.05s remaining)saving best weights -- epoch 58\n",
            "\n",
            "EPOCH: 59.000  train_loss: 0.118  validation_loss: 0.286  validation_char_acc: 0.928  validation_word_acc: 0.789  train_char_acc: 0.988  train_word_acc: 0.939  (23754.20s - 16507.16s remaining)\n",
            "\n",
            "Pred: `indisitudity` :: Truth: `individuality`\n",
            "Pred: `we` :: Truth: `we`\n",
            "Pred: `firm` :: Truth: `firm`\n",
            "Pred: `listen` :: Truth: `listen`\n",
            "Pred: `necessary` :: Truth: `necessary`\n",
            "test img: tite\n",
            "\n",
            "EPOCH: 60.000  train_loss: 0.118  validation_loss: 0.287  validation_char_acc: 0.927  validation_word_acc: 0.786  train_char_acc: 0.988  train_word_acc: 0.939  (23953.40s - 15968.94s remaining)\n",
            "\n",
            "Pred: `fact` :: Truth: `fact`\n",
            "Pred: `whether` :: Truth: `whether`\n",
            "Pred: `must` :: Truth: `must`\n",
            "Pred: `simply` :: Truth: `simply`\n",
            "Pred: `rise` :: Truth: `rise`\n",
            "test img: fie\n",
            "\n",
            "EPOCH: 61.000  validation_loss: 0.248  validation_char_acc: 0.921  validation_word_acc: 0.859  (24151.99s - 15441.44s remaining)saving best weights -- epoch 60\n",
            "\n",
            "EPOCH: 61.000  train_loss: 0.121  validation_loss: 0.288  validation_char_acc: 0.928  validation_word_acc: 0.789  train_char_acc: 0.988  train_word_acc: 0.939  (24152.14s - 15441.53s remaining)\n",
            "\n",
            "Pred: `product` :: Truth: `product`\n",
            "Pred: `control` :: Truth: `control`\n",
            "Pred: `work` :: Truth: `work`\n",
            "Pred: `almost` :: Truth: `almost`\n",
            "Pred: `Rapeil` :: Truth: `Pompeii`\n",
            "test img: pie\n",
            "\n",
            "EPOCH: 62.000  train_loss: 0.116  validation_loss: 0.293  validation_char_acc: 0.928  validation_word_acc: 0.788  train_char_acc: 0.989  train_word_acc: 0.941  (24352.00s - 14925.42s remaining)\n",
            "\n",
            "Pred: `fill` :: Truth: `fill`\n",
            "Pred: `service` :: Truth: `service`\n",
            "Pred: `wear` :: Truth: `wear`\n",
            "Pred: `cxaple` :: Truth: `example`\n",
            "Pred: `house` :: Truth: `house`\n",
            "test img: fie\n",
            "\n",
            "EPOCH: 63.000  train_loss: 0.117  validation_loss: 0.287  validation_char_acc: 0.929  validation_word_acc: 0.788  train_char_acc: 0.989  train_word_acc: 0.940  (24551.86s - 14419.35s remaining)\n",
            "\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `by` :: Truth: `by`\n",
            "Pred: `energy` :: Truth: `energy`\n",
            "Pred: `ropntntie` :: Truth: `temperatures`\n",
            "Pred: `maintain` :: Truth: `maintain`\n",
            "test img: fixe\n",
            "\n",
            "EPOCH: 64.000  train_loss: 0.116  validation_loss: 0.304  validation_char_acc: 0.925  validation_word_acc: 0.779  train_char_acc: 0.989  train_word_acc: 0.942  (24751.49s - 13922.72s remaining)\n",
            "\n",
            "Pred: `table` :: Truth: `table`\n",
            "Pred: `atarmed` :: Truth: `alarmed`\n",
            "Pred: `fonutin` :: Truth: `fontein`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `wrter` :: Truth: `writer`\n",
            "test img: fie\n",
            "\n",
            "EPOCH: 65.000  validation_loss: 0.277  validation_char_acc: 0.948  validation_word_acc: 0.859  (24950.41s - 13434.84s remaining)saving best weights -- epoch 64\n",
            "\n",
            "EPOCH: 65.000  train_loss: 0.116  validation_loss: 0.280  validation_char_acc: 0.930  validation_word_acc: 0.792  train_char_acc: 0.988  train_word_acc: 0.940  (24950.57s - 13434.92s remaining)\n",
            "\n",
            "Pred: `maintaning` :: Truth: `maintaining`\n",
            "Pred: `those` :: Truth: `those`\n",
            "Pred: `effort` :: Truth: `effort`\n",
            "Pred: `full` :: Truth: `full`\n",
            "Pred: `both` :: Truth: `both`\n",
            "test img: pixe\n",
            "\n",
            "EPOCH: 66.000  train_loss: 0.116  validation_loss: 0.287  validation_char_acc: 0.928  validation_word_acc: 0.786  train_char_acc: 0.989  train_word_acc: 0.943  (25149.63s - 12955.87s remaining)\n",
            "\n",
            "Pred: `these` :: Truth: `those`\n",
            "Pred: `in` :: Truth: `'m`\n",
            "Pred: `with` :: Truth: `with`\n",
            "Pred: `statistical` :: Truth: `statistical`\n",
            "Pred: `natural` :: Truth: `natural`\n",
            "test img: tre\n",
            "\n",
            "EPOCH: 67.000  train_loss: 0.115  validation_loss: 0.299  validation_char_acc: 0.926  validation_word_acc: 0.782  train_char_acc: 0.989  train_word_acc: 0.943  (25348.09s - 12484.88s remaining)\n",
            "\n",
            "Pred: `push` :: Truth: `push`\n",
            "Pred: `R.` :: Truth: `R.`\n",
            "Pred: `paper` :: Truth: `paper`\n",
            "Pred: `bifitee` :: Truth: `Griffiths`\n",
            "Pred: `policy` :: Truth: `policy`\n",
            "test img: rie\n",
            "\n",
            "EPOCH: 68.000  train_loss: 0.115  validation_loss: 0.301  validation_char_acc: 0.925  validation_word_acc: 0.783  train_char_acc: 0.989  train_word_acc: 0.942  (25548.90s - 12023.01s remaining)\n",
            "\n",
            "Pred: `break` :: Truth: `break`\n",
            "Pred: `We` :: Truth: `we`\n",
            "Pred: `yet` :: Truth: `yet`\n",
            "Pred: `cause` :: Truth: `cause`\n",
            "Pred: `modern` :: Truth: `modern`\n",
            "test img: tie\n",
            "\n",
            "EPOCH: 69.000  train_loss: 0.115  validation_loss: 0.292  validation_char_acc: 0.927  validation_word_acc: 0.786  train_char_acc: 0.988  train_word_acc: 0.942  (25748.37s - 11568.11s remaining)\n",
            "\n",
            "Pred: `out` :: Truth: `Out`\n",
            "Pred: `ketcher` :: Truth: `kitchen`\n",
            "Pred: `of` :: Truth: `of`\n",
            "Pred: `ohyicat` :: Truth: `physical`\n",
            "Pred: `has` :: Truth: `has`\n",
            "test img: Pie\n",
            "\n",
            "EPOCH: 70.000  train_loss: 0.115  validation_loss: 0.285  validation_char_acc: 0.929  validation_word_acc: 0.789  train_char_acc: 0.989  train_word_acc: 0.943  (25948.48s - 11120.78s remaining)\n",
            "\n",
            "Pred: `reality` :: Truth: `reality`\n",
            "Pred: `our` :: Truth: `our`\n",
            "Pred: `Ps` :: Truth: `MPs`\n",
            "Pred: `to` :: Truth: `to`\n",
            "Pred: `blue` :: Truth: `blue`\n",
            "test img: fire\n",
            "\n",
            "EPOCH: 71.000  train_loss: 0.114  validation_loss: 0.305  validation_char_acc: 0.925  validation_word_acc: 0.778  train_char_acc: 0.989  train_word_acc: 0.944  (26148.18s - 10680.24s remaining)\n",
            "\n",
            "Pred: `of` :: Truth: `of`\n",
            "Pred: `energy` :: Truth: `energy`\n",
            "Pred: `friend` :: Truth: `friend`\n",
            "Pred: `perform` :: Truth: `perform`\n",
            "Pred: `compretorive` :: Truth: `comprehensive`\n",
            "test img: f.te\n",
            "\n",
            "EPOCH: 72.000  train_loss: 0.113  validation_loss: 0.291  validation_char_acc: 0.927  validation_word_acc: 0.787  train_char_acc: 0.989  train_word_acc: 0.944  (26347.66s - 10246.31s remaining)\n",
            "\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `every` :: Truth: `every`\n",
            "Pred: `defense` :: Truth: `defense`\n",
            "Pred: `waakern` :: Truth: `weaken`\n",
            "test img: Mie\n",
            "\n",
            "EPOCH: 73.000  train_loss: 0.113  validation_loss: 0.294  validation_char_acc: 0.927  validation_word_acc: 0.785  train_char_acc: 0.989  train_word_acc: 0.944  (26548.53s - 9819.32s remaining)\n",
            "\n",
            "Pred: `by` :: Truth: `by`\n",
            "Pred: `fine` :: Truth: `fine`\n",
            "Pred: `ware` :: Truth: `were`\n",
            "Pred: `tonight` :: Truth: `tonight`\n",
            "Pred: `threat` :: Truth: `threat`\n",
            "test img: tike\n",
            "\n",
            "EPOCH: 74.000  train_loss: 0.114  validation_loss: 0.289  validation_char_acc: 0.928  validation_word_acc: 0.788  train_char_acc: 0.989  train_word_acc: 0.944  (26748.54s - 9398.14s remaining)\n",
            "\n",
            "Pred: `three` :: Truth: `three`\n",
            "Pred: `tonight` :: Truth: `tonight`\n",
            "Pred: `collection` :: Truth: `collection`\n",
            "Pred: `cmive` :: Truth: `Chinese`\n",
            "Pred: `also` :: Truth: `also`\n",
            "test img: tie\n",
            "\n",
            "EPOCH: 75.000  train_loss: 0.112  validation_loss: 0.292  validation_char_acc: 0.928  validation_word_acc: 0.790  train_char_acc: 0.989  train_word_acc: 0.945  (26947.78s - 8982.59s remaining)\n",
            "\n",
            "Pred: `vividly` :: Truth: `vividly`\n",
            "Pred: `befopre` :: Truth: `before`\n",
            "Pred: `lest` :: Truth: `left`\n",
            "Pred: `2s` :: Truth: `as`\n",
            "Pred: `mission` :: Truth: `mission`\n",
            "test img: fire\n",
            "\n",
            "EPOCH: 76.000  train_loss: 0.115  validation_loss: 0.300  validation_char_acc: 0.924  validation_word_acc: 0.779  train_char_acc: 0.989  train_word_acc: 0.944  (27149.71s - 8573.59s remaining)\n",
            "\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `would` :: Truth: `would`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `billion` :: Truth: `billion`\n",
            "test img: PiKe\n",
            "\n",
            "EPOCH: 77.000  train_loss: 0.113  validation_loss: 0.286  validation_char_acc: 0.928  validation_word_acc: 0.790  train_char_acc: 0.988  train_word_acc: 0.943  (27351.47s - 8169.92s remaining)\n",
            "\n",
            "Pred: `atteantion` :: Truth: `attention`\n",
            "Pred: `like` :: Truth: `like`\n",
            "Pred: `in` :: Truth: `in`\n",
            "Pred: `Committee` :: Truth: `Committee`\n",
            "Pred: `have` :: Truth: `have`\n",
            "test img: Ple\n",
            "\n",
            "EPOCH: 78.000  train_loss: 0.112  validation_loss: 0.301  validation_char_acc: 0.926  validation_word_acc: 0.782  train_char_acc: 0.990  train_word_acc: 0.945  (27551.14s - 7770.83s remaining)\n",
            "\n",
            "Pred: `dity` :: Truth: `ditty`\n",
            "Pred: `mind` :: Truth: `mind`\n",
            "Pred: `being` :: Truth: `being`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `remain` :: Truth: `remain`\n",
            "test img: fiKe\n",
            "\n",
            "EPOCH: 79.000  train_loss: 0.115  validation_loss: 0.294  validation_char_acc: 0.926  validation_word_acc: 0.784  train_char_acc: 0.989  train_word_acc: 0.944  (27751.62s - 7377.01s remaining)\n",
            "\n",
            "Pred: `alality` :: Truth: `quality`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `hold` :: Truth: `hold`\n",
            "Pred: `though` :: Truth: `though`\n",
            "test img: rxe\n",
            "\n",
            "EPOCH: 80.000  train_loss: 0.110  validation_loss: 0.292  validation_char_acc: 0.930  validation_word_acc: 0.791  train_char_acc: 0.990  train_word_acc: 0.946  (27952.58s - 6988.15s remaining)\n",
            "\n",
            "Pred: `of` :: Truth: `of`\n",
            "Pred: `too` :: Truth: `too`\n",
            "Pred: `is` :: Truth: `is`\n",
            "Pred: `raality` :: Truth: `reality`\n",
            "Pred: `the` :: Truth: `the`\n",
            "test img: Pie\n",
            "\n",
            "EPOCH: 81.000  train_loss: 0.111  validation_loss: 0.296  validation_char_acc: 0.928  validation_word_acc: 0.791  train_char_acc: 0.990  train_word_acc: 0.945  (28153.58s - 6603.93s remaining)\n",
            "\n",
            "Pred: `business` :: Truth: `business`\n",
            "Pred: `of` :: Truth: `of`\n",
            "Pred: `Congress` :: Truth: `Congress`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `light` :: Truth: `light`\n",
            "test img: rike\n",
            "\n",
            "EPOCH: 82.000  validation_loss: 0.259  validation_char_acc: 0.937  validation_word_acc: 0.812  (28353.99s - 6224.05s remaining)saving best weights -- epoch 81\n",
            "\n",
            "EPOCH: 82.000  train_loss: 0.112  validation_loss: 0.279  validation_char_acc: 0.931  validation_word_acc: 0.797  train_char_acc: 0.989  train_word_acc: 0.943  (28354.19s - 6224.09s remaining)\n",
            "\n",
            "Pred: `not` :: Truth: `not`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `to` :: Truth: `to`\n",
            "Pred: `agency` :: Truth: `agency`\n",
            "Pred: `effort` :: Truth: `effort`\n",
            "test img: flke\n",
            "\n",
            "EPOCH: 83.000  train_loss: 0.110  validation_loss: 0.291  validation_char_acc: 0.927  validation_word_acc: 0.786  train_char_acc: 0.990  train_word_acc: 0.946  (28554.44s - 5848.50s remaining)\n",
            "\n",
            "Pred: `in` :: Truth: `in`\n",
            "Pred: `inded` :: Truth: `indeed`\n",
            "Pred: `education` :: Truth: `education`\n",
            "Pred: `bank` :: Truth: `bank`\n",
            "Pred: `newspaper` :: Truth: `newspaper`\n",
            "test img: pire\n",
            "\n",
            "EPOCH: 84.000  train_loss: 0.113  validation_loss: 0.293  validation_char_acc: 0.927  validation_word_acc: 0.788  train_char_acc: 0.988  train_word_acc: 0.943  (28754.82s - 5477.11s remaining)\n",
            "\n",
            "Pred: `been` :: Truth: `been`\n",
            "Pred: `international` :: Truth: `international`\n",
            "Pred: `would` :: Truth: `would`\n",
            "Pred: `cillemna` :: Truth: `cisterns`\n",
            "Pred: `on` :: Truth: `on`\n",
            "test img: rire\n",
            "\n",
            "EPOCH: 85.000  train_loss: 0.109  validation_loss: 0.295  validation_char_acc: 0.927  validation_word_acc: 0.788  train_char_acc: 0.990  train_word_acc: 0.946  (28955.34s - 5109.77s remaining)\n",
            "\n",
            "Pred: `gas` :: Truth: `gas`\n",
            "Pred: `defense` :: Truth: `defense`\n",
            "Pred: `image` :: Truth: `image`\n",
            "Pred: `considered` :: Truth: `considered`\n",
            "Pred: `of` :: Truth: `of`\n",
            "test img: rire\n",
            "\n",
            "EPOCH: 86.000  train_loss: 0.112  validation_loss: 0.291  validation_char_acc: 0.927  validation_word_acc: 0.788  train_char_acc: 0.989  train_word_acc: 0.945  (29155.97s - 4746.32s remaining)\n",
            "\n",
            "Pred: `campaion` :: Truth: `campaign`\n",
            "Pred: `goal` :: Truth: `goal`\n",
            "Pred: `some` :: Truth: `some`\n",
            "Pred: `simply` :: Truth: `simply`\n",
            "Pred: `the` :: Truth: `the`\n",
            "test img: re\n",
            "\n",
            "EPOCH: 87.000  train_loss: 0.109  validation_loss: 0.296  validation_char_acc: 0.928  validation_word_acc: 0.788  train_char_acc: 0.990  train_word_acc: 0.947  (29356.54s - 4386.61s remaining)\n",
            "\n",
            "Pred: `telephoned` :: Truth: `telephoned`\n",
            "Pred: `if` :: Truth: `if`\n",
            "Pred: `Britain` :: Truth: `Britain`\n",
            "Pred: `There` :: Truth: `There`\n",
            "Pred: `ok` :: Truth: `ok`\n",
            "test img: rire\n",
            "\n",
            "EPOCH: 88.000  validation_loss: 0.228  validation_char_acc: 0.950  validation_word_acc: 0.875  (29558.38s - 4030.69s remaining)saving best weights -- epoch 87\n",
            "\n",
            "EPOCH: 88.000  train_loss: 0.109  validation_loss: 0.273  validation_char_acc: 0.932  validation_word_acc: 0.798  train_char_acc: 0.990  train_word_acc: 0.947  (29558.60s - 4030.72s remaining)\n",
            "\n",
            "Pred: `in` :: Truth: `in`\n",
            "Pred: `much` :: Truth: `much`\n",
            "Pred: `out` :: Truth: `out`\n",
            "Pred: `Miss` :: Truth: `Miss`\n",
            "Pred: `at` :: Truth: `of`\n",
            "test img: re\n",
            "\n",
            "EPOCH: 89.000  train_loss: 0.111  validation_loss: 0.287  validation_char_acc: 0.929  validation_word_acc: 0.793  train_char_acc: 0.990  train_word_acc: 0.946  (29760.43s - 3678.25s remaining)\n",
            "\n",
            "Pred: `fafe` :: Truth: `safe`\n",
            "Pred: `the` :: Truth: `the`\n",
            "Pred: `than` :: Truth: `than`\n",
            "Pred: `live` :: Truth: `live`\n",
            "Pred: `bill` :: Truth: `bill`\n",
            "test img: pire\n",
            "\n",
            "EPOCH: 90.000  train_loss: 0.108  validation_loss: 0.283  validation_char_acc: 0.930  validation_word_acc: 0.793  train_char_acc: 0.990  train_word_acc: 0.947  (29961.82s - 3329.09s remaining)\n",
            "\n",
            "Pred: `or` :: Truth: `or`\n",
            "Pred: `most` :: Truth: `most`\n",
            "Pred: `never` :: Truth: `never`\n",
            "Pred: `scaring` :: Truth: `scaring`\n",
            "Pred: `now` :: Truth: `now`\n",
            "test img: tike\n",
            "\n",
            "EPOCH: 91.000  train_loss: 0.107  validation_loss: 0.297  validation_char_acc: 0.928  validation_word_acc: 0.791  train_char_acc: 0.990  train_word_acc: 0.947  (30161.79s - 2983.03s remaining)\n",
            "\n",
            "Pred: `air` :: Truth: `air`\n",
            "Pred: `Common` :: Truth: `Common`\n",
            "Pred: `here` :: Truth: `here`\n",
            "Pred: `she` :: Truth: `who`\n",
            "Pred: `alay` :: Truth: `away`\n",
            "test img: pike\n",
            "\n",
            "EPOCH: 92.000  train_loss: 0.109  validation_loss: 0.299  validation_char_acc: 0.926  validation_word_acc: 0.786  train_char_acc: 0.990  train_word_acc: 0.946  (30364.18s - 2640.36s remaining)\n",
            "\n",
            "Pred: `system` :: Truth: `system`\n",
            "Pred: `card` :: Truth: `card`\n",
            "Pred: `support` :: Truth: `support`\n",
            "Pred: `lawyer` :: Truth: `lawyer`\n",
            "Pred: `naten` :: Truth: `motor`\n",
            "test img: lie\n",
            "\n",
            "EPOCH: 93.000  train_loss: 0.109  validation_loss: 0.282  validation_char_acc: 0.930  validation_word_acc: 0.795  train_char_acc: 0.990  train_word_acc: 0.947  (30568.42s - 2300.85s remaining)\n",
            "\n",
            "Pred: `Neiegtion` :: Truth: `Vaughan`\n",
            "Pred: `almost` :: Truth: `almost`\n",
            "Pred: `doo` :: Truth: `does`\n",
            "Pred: `fish` :: Truth: `fish`\n",
            "Pred: `go` :: Truth: `go`\n",
            "test img: rie\n",
            "\n",
            "EPOCH: 94.000  train_loss: 0.107  validation_loss: 0.286  validation_char_acc: 0.930  validation_word_acc: 0.794  train_char_acc: 0.990  train_word_acc: 0.948  (30770.39s - 1964.07s remaining)\n",
            "\n",
            "Pred: `could` :: Truth: `could`\n",
            "Pred: `actity` :: Truth: `activity`\n",
            "Pred: `come` :: Truth: `come`\n",
            "Pred: `short` :: Truth: `short`\n",
            "Pred: `office` :: Truth: `office`\n",
            "test img: tie\n",
            "\n",
            "EPOCH: 95.000  train_loss: 0.109  validation_loss: 0.294  validation_char_acc: 0.926  validation_word_acc: 0.788  train_char_acc: 0.990  train_word_acc: 0.947  (30972.64s - 1630.14s remaining)\n",
            "\n",
            "Pred: `hear` :: Truth: `hear`\n",
            "Pred: `run` :: Truth: `sea`\n",
            "Pred: `indiqunity` :: Truth: `indignity`\n",
            "Pred: `great` :: Truth: `great`\n",
            "Pred: `civil` :: Truth: `civil`\n",
            "test img: Pie\n",
            "\n",
            "EPOCH: 96.000  train_loss: 0.108  validation_loss: 0.292  validation_char_acc: 0.928  validation_word_acc: 0.789  train_char_acc: 0.990  train_word_acc: 0.947  (31173.62s - 1298.90s remaining)\n",
            "\n",
            "Pred: `proper` :: Truth: `proper`\n",
            "Pred: `puostice` :: Truth: `prestige`\n",
            "Pred: `director` :: Truth: `director`\n",
            "Pred: `of` :: Truth: `of`\n",
            "Pred: `funt` :: Truth: `But`\n",
            "test img: the\n",
            "\n",
            "EPOCH: 97.000  train_loss: 0.107  validation_loss: 0.284  validation_char_acc: 0.930  validation_word_acc: 0.792  train_char_acc: 0.990  train_word_acc: 0.948  (31375.65s - 970.38s remaining)\n",
            "\n",
            "Pred: `kind` :: Truth: `kind`\n",
            "Pred: `public` :: Truth: `public`\n",
            "Pred: `of` :: Truth: `at`\n",
            "Pred: `Shamir` :: Truth: `Shamir`\n",
            "Pred: `pager` :: Truth: `pages`\n",
            "test img: rie\n",
            "\n",
            "EPOCH: 98.000  train_loss: 0.109  validation_loss: 0.282  validation_char_acc: 0.930  validation_word_acc: 0.796  train_char_acc: 0.990  train_word_acc: 0.948  (31577.17s - 644.43s remaining)\n",
            "\n",
            "Pred: `to` :: Truth: `to`\n",
            "Pred: `appear` :: Truth: `appear`\n",
            "Pred: `unit` :: Truth: `unit`\n",
            "Pred: `capacity` :: Truth: `capacity`\n",
            "Pred: `different` :: Truth: `different`\n",
            "test img: rire\n",
            "\n",
            "EPOCH: 99.000  train_loss: 0.106  validation_loss: 0.293  validation_char_acc: 0.929  validation_word_acc: 0.791  train_char_acc: 0.990  train_word_acc: 0.948  (31779.29s - 321.00s remaining)\n",
            "\n",
            "Pred: `strategy` :: Truth: `strategy`\n",
            "Pred: `is` :: Truth: `is`\n",
            "Pred: `colelagres` :: Truth: `colleagues`\n",
            "Pred: `Prince` :: Truth: `Prince`\n",
            "Pred: `Lefin` :: Truth: `Levi`\n",
            "test img: pie\n",
            "\n",
            "EPOCH: 100.000  train_loss: 0.108  validation_loss: 0.276  validation_char_acc: 0.931  validation_word_acc: 0.798  train_char_acc: 0.990  train_word_acc: 0.948  (31981.49s - 0.00s remaining)\n",
            "\n",
            "Pred: `society` :: Truth: `society`\n",
            "Pred: `lead` :: Truth: `lead`\n",
            "Pred: `unson` :: Truth: `union`\n",
            "Pred: `natural` :: Truth: `natural`\n",
            "Pred: `of` :: Truth: `of`\n",
            "test img: pie\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from typing import ValuesView\n",
        "from torch.autograd.variable import Variable\n",
        "import shutil\n",
        "early_stop_patience=0\n",
        "ebochs=100\n",
        "lr=0.003\n",
        "optimizer=torch.optim.AdamW(model.parameters(),lr)\n",
        "log=Report(ebochs)\n",
        "N = len(trn_loader)\n",
        "V= len(val_loader)\n",
        "best_val_acc=0\n",
        "for eboch in range(ebochs):\n",
        "  for ix,data in enumerate(trn_loader):\n",
        "    model.train()\n",
        "    pos = eboch+(ix+1)/N\n",
        "    imgs,labels, label_len,targets, input_len = data\n",
        "    optimizer.zero_grad()\n",
        "    preds = model(imgs)\n",
        "    loss=ctc(preds, targets, input_len, label_len)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    eval_res=trn_dataset.evaluate(model,imgs,labels)\n",
        "    log.record(pos=pos, train_loss=loss, train_char_acc=eval_res['char-accuracy'],\n",
        "               train_word_acc=eval_res['word-accuracy'],end='\\r')\n",
        "\n",
        "  val_acc=0\n",
        "  with torch.no_grad():\n",
        "    for ix,data in enumerate(val_loader):\n",
        "      model.eval()\n",
        "      pos = eboch+(ix+1)/V\n",
        "      imgs,labels, label_len,targets, input_len = data\n",
        "      preds = model(imgs)\n",
        "      loss=ctc(preds, targets, input_len, label_len)\n",
        "      eval_res=val_dataset.evaluate(model,imgs,labels)\n",
        "      log.record(pos=pos, validation_loss=loss, validation_char_acc=eval_res['char-accuracy'],\n",
        "               validation_word_acc=eval_res['word-accuracy'], end='\\r')\n",
        "      val_acc+=eval_res['word-accuracy']\n",
        "    if val_acc>best_val_acc:\n",
        "      early_stop_patience=0\n",
        "      best_val_acc=val_acc\n",
        "      torch.save(model.state_dict(),'best.pt')\n",
        "      print('saving best weights -- epoch {}'.format(eboch))\n",
        "      print()\n",
        "    else:\n",
        "      early_stop_patience+=1\n",
        "      if early_stop_patience==30:\n",
        "        print('Early stopping \\nsaving last weights...')\n",
        "        torch.save(model.state_dict(),'last.pt')\n",
        "    log.report_avgs(eboch+1)\n",
        "    print()\n",
        "    for jx in range(5):\n",
        "          img, label = val_dataset.sample()\n",
        "          _img = torch.Tensor(img).float().to(device)[None][None]\n",
        "          pred = model(_img)[:,0,:]\n",
        "          pred = val_dataset.decode(pred)\n",
        "          print(f'Pred: `{pred}` :: Truth: `{label}`')\n",
        "    imahm=cv2.imread('/content/img.jpg',0)\n",
        "    _imahm=torch.Tensor(imahm).float().to(device)[None,None]\n",
        "    pred = model(_imahm)[:,0,:]\n",
        "    pred = val_dataset.decode(pred)\n",
        "    print(\"test img: \"+pred)\n",
        "    if pred==\"fire\":\n",
        "      torch.save(model.state_dict(),'real_time.pt')\n",
        "    print()\n",
        "  torch.save(log,'log.log')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}